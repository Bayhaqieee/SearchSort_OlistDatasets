{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2nn7C2HuZS2VeQCDvDE04",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bayhaqieee/SearchSort_OlistDatasets/blob/main/SearchSort_Olist_Team_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR4ZoyyMoe3u",
        "outputId": "469d86a3-b35b-4b5e-f922-252687c57594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Search - Counting Sort"
      ],
      "metadata": {
        "id": "DwLRkpbI489a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4mn20fLdNkU",
        "outputId": "ea305279-d848-47e1-9845-815d2baafe26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|    | Dataset             | Column                      |   Sort Time |   Binary Search Time |   Total Time |\n",
            "+====+=====================+=============================+=============+======================+==============+\n",
            "|  0 | Geolocation Dataset | geolocation_zip_code_prefix |    0.130619 |             0.215962 |     0.346581 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|  1 | Geolocation Dataset | geolocation_lat             |    0.123619 |             0.825702 |     0.949321 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|  2 | Geolocation Dataset | geolocation_lng             |    0.117843 |             0.8057   |     0.923543 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|  3 | Geolocation Dataset | geolocation_city            |    0.873691 |             0.054933 |     0.928624 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|  4 | Geolocation Dataset | geolocation_state           |    0.710519 |             0.050262 |     0.760781 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|  5 | Sellers Dataset     | seller_id                   |    0.002517 |             0.000162 |     0.002679 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|  6 | Sellers Dataset     | seller_zip_code_prefix      |    0.00055  |             0.000602 |     0.001152 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|  7 | Sellers Dataset     | seller_city                 |    0.001968 |             0.000159 |     0.002127 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n",
            "|  8 | Sellers Dataset     | seller_state                |    0.001549 |             0.000147 |     0.001696 |\n",
            "+----+---------------------+-----------------------------+-------------+----------------------+--------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Load dataset\n",
        "GEO_URL = '/content/drive/MyDrive/Kuliah/Analgo/Dataset/olist_geolocation_dataset.csv'\n",
        "SELLER_URL = '/content/drive/MyDrive/Kuliah/Analgo/Dataset/olist_sellers_dataset.csv'\n",
        "\n",
        "# Load the dataframes\n",
        "try:\n",
        "    geo_df = pd.read_csv(GEO_URL)\n",
        "    seller_df = pd.read_csv(SELLER_URL)\n",
        "except FileNotFoundError:\n",
        "    print(\"Pastikan dataset berada di lokasi yang benar.\")\n",
        "    geo_df = pd.DataFrame()\n",
        "    seller_df = pd.DataFrame()\n",
        "\n",
        "# Fungsi Binary Search\n",
        "def benchmark_binary_search(df, column):\n",
        "    if df.empty or column not in df.columns:\n",
        "        return \"-\"\n",
        "    df_sorted = df.sort_values(by=column)\n",
        "    data = df_sorted[column].dropna().values\n",
        "    if len(data) == 0:\n",
        "        return \"-\"\n",
        "    target = data[len(data)//2]\n",
        "    start = time.time()\n",
        "    low, high = 0, len(data) - 1\n",
        "    str_data = [str(item) for item in data]\n",
        "    str_target = str(target)\n",
        "    while low <= high:\n",
        "        mid = (low + high) // 2\n",
        "        if str_data[mid] == str_target:\n",
        "            break\n",
        "        elif str_data[mid] < str_target:\n",
        "            low = mid + 1\n",
        "        else:\n",
        "            high = mid - 1\n",
        "    end = time.time()\n",
        "    return round(end - start, 6)\n",
        "\n",
        "# Jalankan benchmarking pada semua kolom\n",
        "def run_full_benchmark(df, dataset_name):\n",
        "    results = []\n",
        "    if df.empty:\n",
        "        print(f\"Skipping benchmark for {dataset_name} as dataframe is empty.\")\n",
        "        return []\n",
        "    for col in df.columns:\n",
        "        sort_time = \"-\"\n",
        "        search_time = \"-\"\n",
        "        try:\n",
        "            start = time.time()\n",
        "            df.sort_values(by=col, inplace=False)\n",
        "            sort_time = round(time.time() - start, 6)\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            search_time = benchmark_binary_search(df, col)\n",
        "        except Exception:\n",
        "            pass\n",
        "        if isinstance(sort_time, float) and isinstance(search_time, float):\n",
        "            total = round(sort_time + search_time, 6)\n",
        "        else:\n",
        "            total = \"-\"\n",
        "        results.append([\n",
        "            dataset_name, col, sort_time, search_time, total\n",
        "        ])\n",
        "    return results\n",
        "\n",
        "# Eksekusi benchmark\n",
        "geo_benchmark = run_full_benchmark(geo_df, \"Geolocation Dataset\")\n",
        "seller_benchmark = run_full_benchmark(seller_df, \"Sellers Dataset\")\n",
        "\n",
        "# Gabungkan hasil dan tampilkan\n",
        "all_results = geo_benchmark + seller_benchmark\n",
        "df_summary = pd.DataFrame(all_results, columns=[\"Dataset\", \"Column\", \"Sort Time\", \"Binary Search Time\", \"Total Time\"])\n",
        "print(tabulate(df_summary, headers='keys', tablefmt='grid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jump Search - Heap Sort"
      ],
      "metadata": {
        "id": "l9vHI2zr5EcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from tabulate import tabulate\n",
        "import heapq\n",
        "\n",
        "# Load dataset\n",
        "GEO_URL = '/content/drive/MyDrive/Kuliah/Analgo/Dataset/olist_geolocation_dataset.csv'\n",
        "SELLER_URL = '/content/drive/MyDrive/Kuliah/Analgo/Dataset/olist_sellers_dataset.csv'\n",
        "\n",
        "geo_df = pd.read_csv(GEO_URL)\n",
        "seller_df = pd.read_csv(SELLER_URL)\n",
        "\n",
        "# Heap Sort\n",
        "def benchmark_heap_sort(df, column):\n",
        "    data = df[column].dropna().tolist()\n",
        "    try:\n",
        "        start = time.time()\n",
        "        heapq.heapify(data)\n",
        "        sorted_data = [heapq.heappop(data) for _ in range(len(data))]\n",
        "        end = time.time()\n",
        "        return round(end - start, 6)\n",
        "    except:\n",
        "        return \"-\"\n",
        "\n",
        "# Jump Search\n",
        "def jump_search(arr, x):\n",
        "    n = len(arr)\n",
        "    step = int(math.sqrt(n))\n",
        "    prev = 0\n",
        "    while prev < n and arr[min(step, n)-1] < x:\n",
        "        prev = step\n",
        "        step += int(math.sqrt(n))\n",
        "        if prev >= n:\n",
        "            return -1\n",
        "    for i in range(prev, min(step, n)):\n",
        "        if arr[i] == x:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "def benchmark_jump_search(df, column, target):\n",
        "    try:\n",
        "        data = sorted(df[column].dropna().astype(str).values)\n",
        "        start = time.time()\n",
        "        jump_search(data, str(target))\n",
        "        end = time.time()\n",
        "        return round(end - start, 6)\n",
        "    except:\n",
        "        return \"-\"\n",
        "\n",
        "# Jalankan benchmark untuk semua kolom\n",
        "def run_detailed_benchmark(df, dataset_name):\n",
        "    results = []\n",
        "    for col in df.columns:\n",
        "        sort_time = benchmark_heap_sort(df, col)\n",
        "        try:\n",
        "            target = df[col].dropna().iloc[len(df)//2]\n",
        "            search_time = benchmark_jump_search(df, col, target)\n",
        "        except:\n",
        "            search_time = \"-\"\n",
        "        results.append([dataset_name, col, \"Heap Sort\", sort_time])\n",
        "        results.append([dataset_name, col, \"Jump Search\", search_time])\n",
        "    return results\n",
        "\n",
        "# Tampilkan ringkasan dan total waktu\n",
        "def summarize_results(results):\n",
        "    df = pd.DataFrame(results, columns=[\"Dataset\", \"Column\", \"Operation\", \"Time (s)\"])\n",
        "    pivot = df.pivot_table(index=[\"Dataset\", \"Column\"], columns=\"Operation\", values=\"Time (s)\").reset_index()\n",
        "\n",
        "    # Hitung total waktu jika dua-duanya numerik\n",
        "    def calculate_total(row):\n",
        "        sort_time = row.get(\"Heap Sort\", \"-\")\n",
        "        search_time = row.get(\"Jump Search\", \"-\")\n",
        "        if isinstance(sort_time, (int, float)) and isinstance(search_time, (int, float)):\n",
        "            return round(sort_time + search_time, 6)\n",
        "        return \"-\"\n",
        "\n",
        "    pivot[\"Total Time (s)\"] = pivot.apply(calculate_total, axis=1)\n",
        "    return pivot\n",
        "\n",
        "# Jalankan benchmark\n",
        "geo_results = run_detailed_benchmark(geo_df, \"Geolocation Dataset\")\n",
        "seller_results = run_detailed_benchmark(seller_df, \"Sellers Dataset\")  # Ganti dari produk ke seller\n",
        "\n",
        "# Gabungkan dan tampilkan\n",
        "all_results = geo_results + seller_results\n",
        "summary_df = summarize_results(all_results)\n",
        "\n",
        "# Cetak tabel\n",
        "print(tabulate(summary_df, headers='keys', tablefmt='grid', showindex=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe_Gcxa-5MBJ",
        "outputId": "bf637012-aa46-4167-ae7e-c97ee059f35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Dataset             | Column                      |   Heap Sort |   Jump Search |   Total Time (s) |\n",
            "+=====================+=============================+=============+===============+==================+\n",
            "| Geolocation Dataset | geolocation_city            |    0.690356 |      0.000412 |         0.690768 |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Geolocation Dataset | geolocation_lat             |    0.983726 |      0.000388 |         0.984114 |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Geolocation Dataset | geolocation_lng             |    0.913887 |      0.000283 |         0.91417  |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Geolocation Dataset | geolocation_state           |    1.10639  |      0.000279 |         1.10667  |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Geolocation Dataset | geolocation_zip_code_prefix |    0.737257 |      0.000347 |         0.737604 |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Sellers Dataset     | seller_city                 |    0.002403 |      2.2e-05  |         0.002425 |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Sellers Dataset     | seller_id                   |    0.00259  |      4.2e-05  |         0.002632 |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Sellers Dataset     | seller_state                |    0.001824 |      2.9e-05  |         0.001853 |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n",
            "| Sellers Dataset     | seller_zip_code_prefix      |    0.001843 |      2.6e-05  |         0.001869 |\n",
            "+---------------------+-----------------------------+-------------+---------------+------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jump Search - Merge Sort"
      ],
      "metadata": {
        "id": "-Yxmf-0L7s26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Load dataset\n",
        "GEO_URL = '/content/drive/MyDrive/Kuliah/Analgo/Dataset/olist_geolocation_dataset.csv'\n",
        "SELLER_URL = '/content/drive/MyDrive/Kuliah/Analgo/Dataset/olist_sellers_dataset.csv'\n",
        "\n",
        "geo_df = pd.read_csv(GEO_URL)\n",
        "seller_df = pd.read_csv(SELLER_URL)\n",
        "\n",
        "# Merge Sort\n",
        "def merge_sort(arr):\n",
        "    if len(arr) <= 1:\n",
        "        return arr\n",
        "    mid = len(arr) // 2\n",
        "    left = merge_sort(arr[:mid])\n",
        "    right = merge_sort(arr[mid:])\n",
        "    return merge(left, right)\n",
        "\n",
        "def merge(left, right):\n",
        "    merged = []\n",
        "    i = j = 0\n",
        "    while i < len(left) and j < len(right):\n",
        "        if str(left[i]) <= str(right[j]):\n",
        "            merged.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            merged.append(right[j])\n",
        "            j += 1\n",
        "    merged += left[i:]\n",
        "    merged += right[j:]\n",
        "    return merged\n",
        "\n",
        "def benchmark_merge_sort(df, column):\n",
        "    data = df[column].dropna().tolist()\n",
        "    start = time.time()\n",
        "    merge_sort(data)\n",
        "    end = time.time()\n",
        "    return end - start\n",
        "\n",
        "# Jump Search\n",
        "def jump_search(arr, x):\n",
        "    n = len(arr)\n",
        "    step = int(math.sqrt(n))\n",
        "    prev = 0\n",
        "    while prev < n and arr[min(step, n)-1] < x:\n",
        "        prev = step\n",
        "        step += int(math.sqrt(n))\n",
        "        if prev >= n:\n",
        "            return -1\n",
        "    for i in range(prev, min(step, n)):\n",
        "        if arr[i] == x:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "def benchmark_jump_search(df, column, target):\n",
        "    data = sorted(df[column].dropna().astype(str).values)\n",
        "    start = time.time()\n",
        "    jump_search(data, str(target))\n",
        "    end = time.time()\n",
        "    return end - start\n",
        "\n",
        "# Benchmark semua kolom dalam dataset\n",
        "def run_full_benchmark(df, dataset_name):\n",
        "    results = []\n",
        "    for col in df.columns:\n",
        "        try:\n",
        "            sort_time = benchmark_merge_sort(df, col)\n",
        "        except:\n",
        "            sort_time = \"-\"\n",
        "        try:\n",
        "            target = df[col].dropna().astype(str).iloc[len(df) // 2]\n",
        "            search_time = benchmark_jump_search(df, col, target)\n",
        "        except:\n",
        "            search_time = \"-\"\n",
        "        results.append([\n",
        "            dataset_name,\n",
        "            col,\n",
        "            f\"{sort_time:.6f}\" if isinstance(sort_time, float) else \"-\",\n",
        "            f\"{search_time:.6f}\" if isinstance(search_time, float) else \"-\",\n",
        "            f\"{(sort_time + search_time):.6f}\" if isinstance(sort_time, float) and isinstance(search_time, float) else \"-\"\n",
        "        ])\n",
        "    return results\n",
        "\n",
        "# Jalankan benchmark\n",
        "geo_results = run_full_benchmark(geo_df, \"Geolocation Dataset\")\n",
        "seller_results = run_full_benchmark(seller_df, \"Sellers Dataset\")  # Ganti dari produk ke seller\n",
        "\n",
        "# Gabungkan hasil dan tampilkan\n",
        "columns = [\"Dataset\", \"Column\", \"Merge Sort Time\", \"Jump Search Time\", \"Total Time\"]\n",
        "benchmark_df = pd.DataFrame(geo_results + seller_results, columns=columns)\n",
        "\n",
        "# Tampilkan tabel\n",
        "print(tabulate(benchmark_df, headers='keys', tablefmt='grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YJgprPk77TE",
        "outputId": "72195d45-b7d6-476e-988d-62d0e27cac3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|    | Dataset             | Column                      |   Merge Sort Time |   Jump Search Time |   Total Time |\n",
            "+====+=====================+=============================+===================+====================+==============+\n",
            "|  0 | Geolocation Dataset | geolocation_zip_code_prefix |          6.40993  |           0.000318 |     6.41025  |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|  1 | Geolocation Dataset | geolocation_lat             |         34.6054   |           0.000501 |    34.6059   |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|  2 | Geolocation Dataset | geolocation_lng             |         32.6697   |           0.000259 |    32.6699   |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|  3 | Geolocation Dataset | geolocation_city            |          5.84117  |           0.000271 |     5.84144  |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|  4 | Geolocation Dataset | geolocation_state           |          3.0664   |           0.000161 |     3.06656  |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|  5 | Sellers Dataset     | seller_id                   |          0.008454 |           2.3e-05  |     0.008477 |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|  6 | Sellers Dataset     | seller_zip_code_prefix      |          0.011984 |           1.5e-05  |     0.011999 |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|  7 | Sellers Dataset     | seller_city                 |          0.008135 |           1.3e-05  |     0.008148 |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n",
            "|  8 | Sellers Dataset     | seller_state                |          0.006629 |           1.6e-05  |     0.006646 |\n",
            "+----+---------------------+-----------------------------+-------------------+--------------------+--------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hash Search - Selection Sort"
      ],
      "metadata": {
        "id": "GT2_kPtq_elg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Load datasets\n",
        "GEO_URL = '/content/drive/MyDrive/Kuliah/Analgo/Dataset/olist_geolocation_dataset.csv'\n",
        "SELLER_URL = '/content/drive/MyDrive/Kuliah/Analgo/Dataset/olist_sellers_dataset.csv'\n",
        "\n",
        "geo_df = pd.read_csv(GEO_URL)\n",
        "seller_df = pd.read_csv(SELLER_URL)\n",
        "\n",
        "# Auto sample function\n",
        "def auto_sample(df, max_rows=10000):\n",
        "    return df.sample(n=max_rows, random_state=42) if len(df) > max_rows else df.copy()\n",
        "\n",
        "# Selection sort\n",
        "def selection_sort(arr):\n",
        "    arr = arr.copy()\n",
        "    for i in range(len(arr)):\n",
        "        min_idx = i\n",
        "        for j in range(i+1, len(arr)):\n",
        "            if str(arr[j]) < str(arr[min_idx]):\n",
        "                min_idx = j\n",
        "        arr[i], arr[min_idx] = arr[min_idx], arr[i]\n",
        "    return arr\n",
        "\n",
        "def benchmark_selection_sort(df, column):\n",
        "    data = df[column].dropna().tolist()\n",
        "    start = time.time()\n",
        "    selection_sort(data)\n",
        "    end = time.time()\n",
        "    return end - start\n",
        "\n",
        "# Hash search\n",
        "def hash_search(data_dict, target):\n",
        "    return data_dict.get(target, None)\n",
        "\n",
        "def benchmark_hash_search(df, column, target):\n",
        "    data = df[column].dropna().astype(str).tolist()\n",
        "    hash_map = {val: i for i, val in enumerate(data)}\n",
        "    start = time.time()\n",
        "    hash_search(hash_map, str(target))\n",
        "    end = time.time()\n",
        "    return end - start\n",
        "\n",
        "# Run benchmark on all columns\n",
        "def run_full_benchmark(df, dataset_name):\n",
        "    df = auto_sample(df)\n",
        "    results = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        try:\n",
        "            sort_time = benchmark_selection_sort(df, col)\n",
        "        except Exception as e:\n",
        "            print(f\"[SORT] Error on {col}: {e}\")\n",
        "            sort_time = \"-\"\n",
        "\n",
        "        try:\n",
        "            target = df[col].dropna().iloc[len(df) // 2]\n",
        "            search_time = benchmark_hash_search(df, col, target)\n",
        "        except Exception as e:\n",
        "            print(f\"[HASH] Error on {col}: {e}\")\n",
        "            search_time = \"-\"\n",
        "\n",
        "        if isinstance(sort_time, float) and isinstance(search_time, float):\n",
        "            total_time = sort_time + search_time\n",
        "        else:\n",
        "            total_time = \"-\"\n",
        "\n",
        "        results.append([\n",
        "            dataset_name,\n",
        "            col,\n",
        "            f\"{sort_time:.6f}\" if isinstance(sort_time, float) else \"-\",\n",
        "            f\"{search_time:.6f}\" if isinstance(search_time, float) else \"-\",\n",
        "            f\"{total_time:.6f}\" if isinstance(total_time, float) else \"-\"\n",
        "        ])\n",
        "    return results\n",
        "\n",
        "# Jalankan benchmark\n",
        "geo_results = run_full_benchmark(geo_df, \"Geolocation Dataset\")\n",
        "seller_results = run_full_benchmark(seller_df, \"Sellers Dataset\")  # Ganti dari produk ke seller\n",
        "\n",
        "# Gabungkan hasil dan tampilkan\n",
        "final_results = geo_results + seller_results\n",
        "df_result = pd.DataFrame(final_results, columns=[\"Dataset\", \"Column\", \"Selection Sort Time\", \"Hash Search Time\", \"Total Time\"])\n",
        "\n",
        "print(tabulate(df_result, headers='keys', tablefmt='grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuevRqffMXgB",
        "outputId": "42e197a2-60a6-40c2-e911-ec706b75c832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|    | Dataset             | Column                      |   Selection Sort Time |   Hash Search Time |   Total Time |\n",
            "+====+=====================+=============================+=======================+====================+==============+\n",
            "|  0 | Geolocation Dataset | geolocation_zip_code_prefix |             12.1058   |            7e-06   |    12.1058   |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|  1 | Geolocation Dataset | geolocation_lat             |             83.2189   |            1.2e-05 |    83.2189   |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|  2 | Geolocation Dataset | geolocation_lng             |             81.5352   |            8e-06   |    81.5352   |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|  3 | Geolocation Dataset | geolocation_city            |              6.83613  |            4e-06   |     6.83613  |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|  4 | Geolocation Dataset | geolocation_state           |              5.02863  |            4e-06   |     5.02864  |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|  5 | Sellers Dataset     | seller_id                   |              0.46631  |            3e-06   |     0.466313 |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|  6 | Sellers Dataset     | seller_zip_code_prefix      |              1.04842  |            6e-06   |     1.04842  |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|  7 | Sellers Dataset     | seller_city                 |              0.475134 |            3e-06   |     0.475137 |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n",
            "|  8 | Sellers Dataset     | seller_state                |              0.444897 |            1e-06   |     0.444899 |\n",
            "+----+---------------------+-----------------------------+-----------------------+--------------------+--------------+\n"
          ]
        }
      ]
    }
  ]
}